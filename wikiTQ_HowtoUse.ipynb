{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfc10109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5335562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\ripx0\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\Stanford--wikitablequestions\\4845d83f334ed5e4a8e0420731e64d57f696feb62e7d3a47b84037864fb8317c (last modified on Sun Nov  3 18:33:20 2024) since it couldn't be found locally at Stanford/wikitablequestions, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'question', 'answers', 'table'],\n",
      "        num_rows: 11321\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'question', 'answers', 'table'],\n",
      "        num_rows: 4344\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'question', 'answers', 'table'],\n",
      "        num_rows: 2831\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 로드\n",
    "dataset = load_dataset(\"Stanford/wikitablequestions\", trust_remote_code=True)\n",
    "\n",
    "# 데이터셋 구조 확인\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "218d0377",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiTQ:\n",
    "    def __init__(self, dataset, index):\n",
    "        \"\"\"데이터셋과 인덱스를 받아 객체를 초기화합니다.\"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.index = index\n",
    "        self._extract_data()  # 내부 데이터 추출\n",
    "\n",
    "    def _extract_data(self):\n",
    "        \"\"\"데이터에서 테이블과 관련된 정보를 추출하여 저장\"\"\"\n",
    "        entry = self.dataset['train'][self.index]\n",
    "\n",
    "        # 테이블 정보 추출 및 DataFrame 생성\n",
    "        self.table_header = entry['table']['header']\n",
    "        self.table_rows = entry['table']['rows']\n",
    "        self.df = pd.DataFrame(self.table_rows, columns=self.table_header)\n",
    "\n",
    "        # 기타 정보 추출\n",
    "        self.question = entry['question']\n",
    "        self.answers = entry['answers']\n",
    "\n",
    "    # Getter 메서드들\n",
    "    def get_table(self):\n",
    "        \"\"\"테이블(DataFrame) 반환\"\"\"\n",
    "        return self.df\n",
    "\n",
    "    def get_question(self):\n",
    "        \"\"\"질문 반환\"\"\"\n",
    "        return self.question\n",
    "\n",
    "    def get_answers(self):\n",
    "        \"\"\"정답 목록 반환\"\"\"\n",
    "        return self.answers\n",
    "\n",
    "    def display_all(self):\n",
    "        \"\"\"모든 정보를 출력\"\"\"\n",
    "        print(\"Table DataFrame:\")\n",
    "        print(self.df)\n",
    "        print(\"\\nQuestion:\", self.question)\n",
    "        print(\"\\nAnswers:\", self.answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a9e5b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "# Set OpenAI client\n",
    "client = openai.Client(api_key='API KEY')\n",
    "model = \"gpt-4o-mini-2024-07-18\"\n",
    "# Create a text file to store results\n",
    "output_file = 'table_comparison.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5cc673",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index_list = [i for i in range(1, 11)]\n",
    "# df_list = []\n",
    "# question_list = []\n",
    "# answer_list = []\n",
    "# # 객체 생성\n",
    "# missed_count = 0\n",
    "# correct_count = 0\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    for index in index_list:\n",
    "        wiki_tq = WikiTQ(dataset, index)\n",
    "\n",
    "        # 메서드 사용 예시\n",
    "        df = wiki_tq.get_table()\n",
    "        question = wiki_tq.get_question()\n",
    "        answer = wiki_tq.get_answers()\n",
    "        \n",
    "        # print(question)\n",
    "        # print(df)\n",
    "        # print(answer)\n",
    "        \n",
    "        table_string = df.to_string(index=False)\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        I have a table extracted from a dataset. The column headers are misaligned and do not clearly match the values in the rows. Here is an example of the table:\\n\\n\n",
    "        Original Table:\\n\n",
    "        col: Rank | Cyclist | Team | Time | UCI ProTour; Points\\n\n",
    "        row1: 1 | Alejandro Valverde (ESP) | Caisse d’Epargne | 5h 29’ 10\" | 40\\n\n",
    "        row 2 : 2 | Alexandr Kolobnev (RUS) | Team CSC Saxo Bank | s.t. | 30\\n\n",
    "        row 3 : 3 | Davide Rebellin (ITA) | Gerolsteiner | s.t. | 25\\n\\n\n",
    "        Desired Restructured Table:\\n\n",
    "        Rank | Cyclist (Country) | Team | Time | UCI ProTour; Points\\n\n",
    "        row1: 1 | Alejandro Valverde (ESP) | Caisse d’Epargne | 5h 29’ 10\" | 40\\n\n",
    "        row 2 : 2 | Alexandr Kolobnev (RUS) | Team CSC Saxo Bank | s.t. | 30\\n\n",
    "        row 3 : 3 | Davide Rebellin (ITA) | Gerolsteiner | s.t. | 25\\n\\n\n",
    "        Your task is to analyze the table, identify misaligned headers, and adjust them to match the structure of the data. Maintain the integrity of the original values and ensure that the output table is clean and readable.\\n\n",
    "        Now, please restructure the following table:\\n\\n\n",
    "\n",
    "        {table_string}\\n\\n\n",
    "        Output the corrected table only, without additional explanations.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Call the OpenAI model\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful data analyst.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Extract and display the response\n",
    "        structured_table = response.choices[0].message.content\n",
    "        \n",
    "        try:\n",
    "            # Convert the structured table to DataFrame\n",
    "            modified_df = pd.read_csv(StringIO(structured_table), sep=\"|\")\n",
    "            modified_df.columns = [col.strip() for col in modified_df.columns]\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to parse the restructured table for index {index}. Error:\", e)\n",
    "            modified_df = pd.DataFrame()  # Placeholder if parsing fails\n",
    "\n",
    "        # Write the original and restructured tables to the text file\n",
    "        f.write(f\"\\n--- Table {index} ---\\n\")\n",
    "        f.write(\"Original Table:\\n\")\n",
    "        f.write(table_string)\n",
    "        f.write(\"\\n\\nRestructured Table:\\n\")\n",
    "        f.write(structured_table)\n",
    "        f.write(\"\\n\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
